{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Search \n",
    "This is a simple search engine that uses Wikipedia movie plot data to search for movies. The data for this project is from https://www.kaggle.com/jrobischon/wikipedia-movie-plots. We are going to look at a subset of the data, specifically American films from 1972-2017."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data\n",
    "The first thing we need to do (after downloading the data and moving it to the appropriate directory) is to load and process the data. We can use the pandas library to read the csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"archive/wiki_movie_plots_deduped.csv\", nrows=17378-8796, \n",
    "            usecols=[\"Title\", \"Plot\"], skiprows=[i for i in range(1, 8796)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number 8796 is the row of The Godfather, which is the first movie in our dataset. We are reading rows 8796 to 17378 because 17378 is the final American movie. To find similar movies, only the title and plot matter, so only those columns will be loaded. Here is some of the data, before preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>In 1945, at his daughter Connie's wedding, Vit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Grave of the Vampire</td>\n",
       "      <td>Several years after his death by electrocution...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Great Northfield Minnesota Raid</td>\n",
       "      <td>In the mid-1870s, outlaws Jesse James, Cole Yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hammer</td>\n",
       "      <td>B.J. Hammer is a boxer who rises up the ranks ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hammersmith Is Out</td>\n",
       "      <td>Billy Breedlove (Beau Bridges) is an orderly a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Title  \\\n",
       "0                        The Godfather   \n",
       "1                 Grave of the Vampire   \n",
       "2  The Great Northfield Minnesota Raid   \n",
       "3                               Hammer   \n",
       "4                   Hammersmith Is Out   \n",
       "\n",
       "                                                Plot  \n",
       "0  In 1945, at his daughter Connie's wedding, Vit...  \n",
       "1  Several years after his death by electrocution...  \n",
       "2  In the mid-1870s, outlaws Jesse James, Cole Yo...  \n",
       "3  B.J. Hammer is a boxer who rises up the ranks ...  \n",
       "4  Billy Breedlove (Beau Bridges) is an orderly a...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming Data\n",
    "Now that we have some data loaded, we can preprocess it to remove unecessary information. NLTK is a good library for NLP processing, so we will use it to remove stopwords (words that don't add much meaning, like prepositions) and to lemmatize word (transform words into a base meaning, like changing dogs -> dog, or ran -> runs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex as re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lem = WordNetLemmatizer()\n",
    "def preprocess(text):\n",
    "    text = re.split('\\W+', text.lower())\n",
    "    for i in range(len(text)):\n",
    "        if text[i] in stop_words:\n",
    "            text[i] = ''\n",
    "        else:\n",
    "            text[i] = lem.lemmatize(text[i])\n",
    "    return ' '.join([t for t in text if t != ''])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use this to process the Plot fields of our data entries, and we will also strip excess spaces from all titles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Plot\"] = data.Plot.apply(lambda x: preprocess(x))\n",
    "data[\"Title\"] = data.Title.apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of our processed data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>1945 daughter connie wedding vito corleone hea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Grave of the Vampire</td>\n",
       "      <td>several year death electrocution late 1930s gh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Great Northfield Minnesota Raid</td>\n",
       "      <td>mid 1870s outlaw jesse james cole younger brot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hammer</td>\n",
       "      <td>b j hammer boxer rise rank help mafia however ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hammersmith Is Out</td>\n",
       "      <td>billy breedlove beau bridge orderly texas psyc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Title  \\\n",
       "0                        The Godfather   \n",
       "1                 Grave of the Vampire   \n",
       "2  The Great Northfield Minnesota Raid   \n",
       "3                               Hammer   \n",
       "4                   Hammersmith Is Out   \n",
       "\n",
       "                                                Plot  \n",
       "0  1945 daughter connie wedding vito corleone hea...  \n",
       "1  several year death electrocution late 1930s gh...  \n",
       "2  mid 1870s outlaw jesse james cole younger brot...  \n",
       "3  b j hammer boxer rise rank help mafia however ...  \n",
       "4  billy breedlove beau bridge orderly texas psyc...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing TF-IDF and top words\n",
    "With processed data, we can begin to analyze significant words from the movie plots. We will use TF-IDF (https://en.wikipedia.org/wiki/Tf%E2%80%93idf) to do this. It will measure how frequently words occur in a document (or a movie plot in this case) compared to how often they occur overall. The scikit-learn library can do this for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# vectorize the data, excluding words that appear in 67% of documents because they don't add much\n",
    "vectorizer = TfidfVectorizer(max_df=0.67)\n",
    "tfidf = vectorizer.fit_transform(data[\"Plot\"])\n",
    "vocab = vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us tfidf, which is a matrix of the TF-IDF value of each word in our vocabulary. Its shape is (num movies, vocabulary size). The vocab variable is a list of all vocabulary words that correspond to the columns in tfidf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8582, 63008)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will iterate through the in data, retrieving the k (30 in this case) words with the highest TF-IDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding most significant words from each movie: 100%|████████████████████████████| 8582/8582 [00:08<00:00, 1044.41it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "movies = defaultdict(set)\n",
    "\n",
    "# iterate through movies and find the top words from the TF-IDF, and store them as a set\n",
    "for i in tqdm(range(data.shape[0]), desc=\"Finding most significant words from each movie\"):\n",
    "    ind = np.argpartition(tfidf[i,].toarray()[0], kth=-30)[-30:]\n",
    "    movies[data.at[i, 'Title']] = set([(vocab[j], tfidf[i,j]) for j in ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use the movies dictionary to get the top 30 words for a specific movie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('ability', 0.05023911245338008),\n",
       " ('access', 0.0383855674985188),\n",
       " ('agent', 0.09303283017579299),\n",
       " ('bioelectric', 0.03894345135734841),\n",
       " ('crew', 0.06075507112063451),\n",
       " ('cypher', 0.07212175647577178),\n",
       " ('exit', 0.03789617058987142),\n",
       " ('group', 0.0427386133877418),\n",
       " ('human', 0.11079063559694462),\n",
       " ('machine', 0.08280320616907191),\n",
       " ('matrix', 0.4506542094573121),\n",
       " ('morpheus', 0.5769740518061742),\n",
       " ('nebuchadnezzar', 0.07212175647577178),\n",
       " ('neo', 0.49581344455108795),\n",
       " ('one', 0.038166733169273305),\n",
       " ('oracle', 0.05916212562626638),\n",
       " ('pacified', 0.03725725417687604),\n",
       " ('physical', 0.03727494045197177),\n",
       " ('pill', 0.0651405147670937),\n",
       " ('powerful', 0.03632334975913562),\n",
       " ('real', 0.03718958592192831),\n",
       " ('reality', 0.037694934615135435),\n",
       " ('sentinel', 0.06112825333045781),\n",
       " ('smith', 0.07399224112022805),\n",
       " ('superhuman', 0.07718088509707786),\n",
       " ('tank', 0.03817229048239077),\n",
       " ('telephone', 0.04144006273570241),\n",
       " ('trinity', 0.1557961820755298),\n",
       " ('world', 0.06986150798029378),\n",
       " ('zion', 0.0702657939303276)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies['The Matrix']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search\n",
    "Using our movies dictionary we can search for specific keywords/titles. We will iterate through all of our movies, finding the union between a user's query and a movie's title or plot. The top 5 movies based on title/plot will be printed for each query. After the first query, the queries will find matches very quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter a movie title or a description of a movie, or 'quit' to stop: star wars luke skywalker darth vader yoda jedi\n",
      "Movie titles most similar to 'star wars luke skywalker darth vader yoda jedi':\n",
      "\t1. Star Wars: The Last Jedi\n",
      "\t2. Star Wars: The Clone Wars\n",
      "\t3. Star Wars Episode IV: A New Hope (aka Star Wars)\n",
      "\t4. Rogue One: A Star Wars Story (film)\n",
      "\t5. Wish Upon a Star\n",
      "Movie plots most similar to 'star wars luke skywalker darth vader yoda jedi':\n",
      "\t1. Return of the Jedi\n",
      "\t2. The Empire Strikes Back\n",
      "\t3. Star Wars Episode IV: A New Hope (aka Star Wars)\n",
      "\t4. Star Wars: Episode III – Revenge of the Sith\n",
      "\t5. First Kid\n",
      "\n",
      "Enter a movie title or a description of a movie, or 'quit' to stop: quit\n"
     ]
    }
   ],
   "source": [
    "movie_count = 5\n",
    "while True:\n",
    "    text = input(\"\\nEnter a movie title or a description of a movie, or 'quit' to stop: \")\n",
    "    if text == 'quit':\n",
    "        break\n",
    "    plot = set(preprocess(text).split()) # preprocess the query to match plots (lemmatized)\n",
    "    title = set(text.lower().split()) - stop_words # not lemmatized to match exact wording of title\n",
    "    share_plot = []\n",
    "    share_title = []\n",
    "\n",
    "    for m in movies:\n",
    "        s = set(m.lower().split())\n",
    "        shared = len(s & title)\n",
    "        if shared: # add titles that share words\n",
    "            share_title.append((shared, m))\n",
    "\n",
    "        score = 0\n",
    "        for word, val in movies[m]: # words that are more specific will have higher vals, let's account for this\n",
    "            if word in plot:\n",
    "                score += val\n",
    "        if score: # add plots that share words\n",
    "            share_plot.append((score, m))\n",
    "\n",
    "    share_title.sort(reverse=True)\n",
    "    print(f\"Movie titles most similar to '{text}':\")\n",
    "    for i in range(min(movie_count, len(share_title))):\n",
    "        print(f\"\\t{i+1}. {share_title[i][1]}\")\n",
    "        \n",
    "    share_plot.sort(reverse=True)\n",
    "    print(f\"Movie plots most similar to '{text}':\")\n",
    "    for i in range(min(movie_count, len(share_plot))):\n",
    "        print(f\"\\t{i+1}. {share_plot[i][1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "This project was very fun to make and is pretty good for finding similar movies. It is very simple and could be expanded using deep learning. One way to do that would be to use a bidirectional LSTM, which may do better to catch context of what's happening rather than treating the words independently. Then the model could understand the meaning of queries more instead of only seeing the words individually."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
